{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploration Notebook\n",
        "\n",
        "This notebook is for exploring and experimenting with the document reasoning agent.\n",
        "\n",
        "## Features:\n",
        "- Document loading and chunking\n",
        "- Embedding visualization\n",
        "- Retrieval testing\n",
        "- Agent interaction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary modules\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Add parent directory to path\n",
        "sys.path.insert(0, str(Path().absolute().parent))\n",
        "\n",
        "from src.retrieval.chunker import chunk_text, semantic_chunk_text, chunk_pdf\n",
        "from src.retrieval.retriever import Retriever\n",
        "from src.retrieval.embedder import Embedder\n",
        "from src.agent.agent import Agent\n",
        "from src.agent.planner import plan\n",
        "from src.agent.worker import Worker\n",
        "from src.llm.local_model_client import LocalModelClient\n",
        "\n",
        "# Configure matplotlib for inline display\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Document Chunking Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample text for exploration\n",
        "sample_text = \"\"\"\n",
        "Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience.\n",
        "Deep learning uses neural networks with multiple layers to process complex patterns in data.\n",
        "Natural language processing handles text data and enables machines to understand human language.\n",
        "Supervised learning uses labeled data to train models that can make predictions.\n",
        "Unsupervised learning finds patterns in data without labeled examples.\n",
        "Reinforcement learning trains agents through rewards and penalties in an environment.\n",
        "\"\"\"\n",
        "\n",
        "# Fixed-size chunking\n",
        "fixed_chunks = chunk_text(sample_text, size=100)\n",
        "print(f\"Fixed-size chunks: {len(fixed_chunks)}\")\n",
        "for i, chunk in enumerate(fixed_chunks, 1):\n",
        "    print(f\"\\nChunk {i} ({len(chunk)} chars): {chunk[:80]}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize chunk size distribution\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Fixed-size chunks\n",
        "fixed_sizes = [len(chunk) for chunk in fixed_chunks]\n",
        "ax1.bar(range(1, len(fixed_chunks) + 1), fixed_sizes, color='steelblue', alpha=0.7)\n",
        "ax1.set_xlabel('Chunk Number')\n",
        "ax1.set_ylabel('Chunk Size (characters)')\n",
        "ax1.set_title('Fixed-Size Chunking')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Semantic chunks\n",
        "semantic_sizes = [len(chunk) for chunk in semantic_chunks]\n",
        "ax2.bar(range(1, len(semantic_chunks) + 1), semantic_sizes, color='coral', alpha=0.7)\n",
        "ax2.set_xlabel('Chunk Number')\n",
        "ax2.set_ylabel('Chunk Size (characters)')\n",
        "ax2.set_title('Semantic Chunking')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nFixed-size: {len(fixed_chunks)} chunks, avg size: {np.mean(fixed_sizes):.1f} chars\")\n",
        "print(f\"Semantic: {len(semantic_chunks)} chunks, avg size: {np.mean(semantic_sizes):.1f} chars\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Semantic chunking\n",
        "semantic_chunks = semantic_chunk_text(sample_text, max_chunk_size=200)\n",
        "print(f\"Semantic chunks: {len(semantic_chunks)}\")\n",
        "for i, chunk in enumerate(semantic_chunks, 1):\n",
        "    print(f\"\\nChunk {i} ({len(chunk)} chars): {chunk[:80]}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize retrieval scores\n",
        "scored_results = retriever.retrieve_with_scores(query, k=5)\n",
        "chunks_labels = [f\"Chunk {i+1}\" for i in range(len(scored_results))]\n",
        "scores = [score for _, score in scored_results]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.barh(chunks_labels, scores, color='teal', alpha=0.7)\n",
        "plt.xlabel('Similarity Score', fontsize=12)\n",
        "plt.ylabel('Retrieved Chunks', fontsize=12)\n",
        "plt.title(f'Retrieval Scores for Query: \"{query}\"', fontsize=14)\n",
        "plt.xlim(0, 1)\n",
        "plt.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, (bar, score) in enumerate(zip(bars, scores)):\n",
        "    plt.text(score + 0.02, i, f'{score:.3f}', va='center', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nTop {len(scored_results)} chunks retrieved:\")\n",
        "for i, (chunk, score) in enumerate(scored_results, 1):\n",
        "    print(f\"{i}. Score: {score:.3f} - {chunk[:60]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Retrieval System Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize embedding similarity matrix\n",
        "embedder = Embedder()\n",
        "chunk_embeddings = embedder.embed(fixed_chunks[:5])  # First 5 chunks\n",
        "\n",
        "# Calculate similarity matrix\n",
        "similarity_matrix = np.dot(chunk_embeddings, chunk_embeddings.T)\n",
        "norms = np.linalg.norm(chunk_embeddings, axis=1, keepdims=True)\n",
        "similarity_matrix = similarity_matrix / (norms * norms.T)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "im = plt.imshow(similarity_matrix, cmap='viridis', aspect='auto')\n",
        "plt.colorbar(im, label='Cosine Similarity')\n",
        "plt.xlabel('Chunk Index')\n",
        "plt.ylabel('Chunk Index')\n",
        "plt.title('Chunk Embedding Similarity Matrix', fontsize=14)\n",
        "plt.xticks(range(len(fixed_chunks[:5])), range(1, len(fixed_chunks[:5]) + 1))\n",
        "plt.yticks(range(len(fixed_chunks[:5])), range(1, len(fixed_chunks[:5]) + 1))\n",
        "\n",
        "# Add text annotations\n",
        "for i in range(len(fixed_chunks[:5])):\n",
        "    for j in range(len(fixed_chunks[:5])):\n",
        "        text = plt.text(j, i, f'{similarity_matrix[i, j]:.2f}',\n",
        "                       ha=\"center\", va=\"center\", color=\"white\", fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup retriever\n",
        "retriever = Retriever()\n",
        "retriever.index_chunks(fixed_chunks)\n",
        "\n",
        "# Test retrieval\n",
        "query = \"What is machine learning?\"\n",
        "results = retriever.retrieve(query, k=3)\n",
        "print(f\"Query: '{query}'\")\n",
        "print(f\"\\nRetrieved {len(results)} chunks:\")\n",
        "for i, chunk in enumerate(results, 1):\n",
        "    print(f\"\\n{i}. {chunk}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrieve with scores\n",
        "scored_results = retriever.retrieve_with_scores(query, k=3)\n",
        "print(f\"Query: '{query}'\")\n",
        "print(f\"\\nRetrieved chunks with similarity scores:\")\n",
        "for i, (chunk, score) in enumerate(scored_results, 1):\n",
        "    print(f\"\\n{i}. Score: {score:.3f}\")\n",
        "    print(f\"   {chunk[:100]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Agent Interaction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup agent\n",
        "model = LocalModelClient()\n",
        "worker = Worker(retriever, model)\n",
        "agent = Agent(plan, worker, model)\n",
        "\n",
        "# Test query\n",
        "query = \"What is deep learning?\"\n",
        "print(f\"Query: '{query}'\")\n",
        "try:\n",
        "    answer = agent.run(query)\n",
        "    print(f\"\\nAnswer: {answer}\")\n",
        "except NotImplementedError:\n",
        "    print(\"\\n(Note: Local model not loaded - this is expected without model_name)\")\n",
        "    print(\"The agent structure is working correctly!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
