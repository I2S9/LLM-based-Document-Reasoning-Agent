{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation Notebook\n",
        "\n",
        "This notebook is for evaluating and benchmarking the document reasoning agent.\n",
        "\n",
        "## Features:\n",
        "- Metric calculation\n",
        "- Benchmark execution\n",
        "- Model comparison\n",
        "- Results visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary modules\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "# Add parent directory to path\n",
        "sys.path.insert(0, str(Path().absolute().parent))\n",
        "\n",
        "from src.evaluation.metrics import simple_similarity, chunk_relevance, measure_latency\n",
        "from src.evaluation.benchmark import Benchmark\n",
        "from src.agent.agent import Agent\n",
        "from src.agent.planner import plan\n",
        "from src.agent.worker import Worker\n",
        "from src.retrieval.retriever import Retriever\n",
        "from src.retrieval.chunker import chunk_text\n",
        "from src.llm.local_model_client import LocalModelClient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Metric Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test similarity metric\n",
        "text1 = \"Machine learning is a subset of artificial intelligence\"\n",
        "text2 = \"Machine learning uses algorithms to learn from data\"\n",
        "similarity = simple_similarity(text1, text2)\n",
        "print(f\"Text 1: '{text1}'\")\n",
        "print(f\"Text 2: '{text2}'\")\n",
        "print(f\"Similarity: {similarity:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test chunk relevance\n",
        "chunks = [\n",
        "    \"Machine learning is a subset of AI\",\n",
        "    \"Deep learning uses neural networks\",\n",
        "    \"Natural language processing handles text\"\n",
        "]\n",
        "query = \"machine learning artificial intelligence\"\n",
        "relevance = chunk_relevance(chunks, query)\n",
        "print(f\"Query: '{query}'\")\n",
        "print(f\"Chunks: {len(chunks)}\")\n",
        "print(f\"Average relevance: {relevance:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Benchmark Execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup for benchmark\n",
        "retriever = Retriever()\n",
        "test_text = \"\"\"\n",
        "Machine learning is a subset of artificial intelligence.\n",
        "Deep learning uses neural networks with multiple layers.\n",
        "Natural language processing handles text data.\n",
        "Supervised learning uses labeled data to train models.\n",
        "\"\"\"\n",
        "chunks = chunk_text(test_text, size=50)\n",
        "retriever.index_chunks(chunks)\n",
        "\n",
        "model = LocalModelClient()\n",
        "worker = Worker(retriever, model)\n",
        "agent = Agent(plan, worker, model)\n",
        "\n",
        "benchmark = Benchmark(agent, retriever)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define test cases\n",
        "test_cases = [\n",
        "    {\n",
        "        \"query\": \"What is machine learning?\",\n",
        "        \"ground_truth\": \"Machine learning is a subset of artificial intelligence\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What is deep learning?\",\n",
        "        \"ground_truth\": \"Deep learning uses neural networks with multiple layers\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What is supervised learning?\",\n",
        "        \"ground_truth\": \"Supervised learning uses labeled data to train models\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"Test cases: {len(test_cases)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run benchmark\n",
        "try:\n",
        "    summary = benchmark.run_benchmark(test_cases, k=3)\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"BENCHMARK RESULTS\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Number of queries: {summary['num_queries']}\")\n",
        "    print(f\"Average latency: {summary['avg_latency']:.4f} seconds\")\n",
        "    print(f\"Average similarity: {summary['avg_similarity']:.3f}\")\n",
        "    print(f\"Average chunk relevance: {summary['avg_chunk_relevance']:.3f}\")\n",
        "    \n",
        "    print(\"\\nDetailed Results:\")\n",
        "    for i, result in enumerate(summary['results'], 1):\n",
        "        print(f\"\\nQuery {i}: '{result['query']}'\")\n",
        "        print(f\"  Latency: {result['latency']:.4f}s\")\n",
        "        print(f\"  Similarity: {result['similarity']:.3f}\")\n",
        "        print(f\"  Chunk relevance: {result['chunk_relevance']:.3f}\")\n",
        "        \n",
        "except NotImplementedError:\n",
        "    print(\"(Note: Local model not loaded - benchmark structure is correct)\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
